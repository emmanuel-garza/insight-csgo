{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitminiconda3virtualenv7f2e9c966dbc4598b4ce375409bf61d2",
   "display_name": "Python 3.7.4 64-bit ('miniconda3': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modues to be used\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from pickle files\n",
    "\n",
    "# -> Player dictionary with the dataFrames\n",
    "f = open('../data/dict_player.pickle', 'rb')\n",
    "dict_player = pickle.load(f)\n",
    "\n",
    "# -> Map dataFrames\n",
    "f = open('../data/df_map.pickle','rb')\n",
    "df_map = pickle.load(f)\n",
    "\n",
    "# -> Map dictionary\n",
    "f = open('../data/dict_map.pickle','rb')\n",
    "dict_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "10466\n0:04:05.194947\n"
    }
   ],
   "source": [
    "DAYS_WEIGHT = 365\n",
    "\n",
    "time_1 = datetime.now()\n",
    "\n",
    "# If we want matches only between only ranked teams\n",
    "df_tmp = df_map[ (df_map['date']>datetime(2019,1,1)) &\n",
    "    ( (df_map['team_rank_1']>0) & (df_map['team_rank_2']>0) ) ]\n",
    "\n",
    "\n",
    "\n",
    "dict_train = {}\n",
    "\n",
    "print( len( df_tmp['map_id']) )\n",
    "\n",
    "for map_id in df_tmp['map_id'][:2000]:\n",
    "\n",
    "    map_date = df_tmp.loc[map_id]['date']\n",
    "\n",
    "    dict_train[map_id] = {}    \n",
    "\n",
    "    # Here we are taking the rankings to be non-zero\n",
    "    rank_1 = df_tmp.loc[map_id]['team_rank_1']\n",
    "    rank_2 = df_tmp.loc[map_id]['team_rank_2']\n",
    "\n",
    "    winner = df_tmp.loc[map_id]['winner']\n",
    "\n",
    "    if rank_1 < rank_2:\n",
    "        fav = 0\n",
    "        dict_train[map_id]['rank_dif'] = rank_2-rank_1\n",
    "\n",
    "        if winner == 1:\n",
    "            dict_train[map_id]['fav_win'] = 1\n",
    "        else:\n",
    "            dict_train[map_id]['fav_win'] = 0\n",
    "\n",
    "    else:\n",
    "        fav = 1\n",
    "        dict_train[map_id]['rank_dif'] = rank_1-rank_2\n",
    "\n",
    "        if winner == 2:\n",
    "            dict_train[map_id]['fav_win'] = 1\n",
    "        else:\n",
    "            dict_train[map_id]['fav_win'] = 0\n",
    "\n",
    "    count_team = -1\n",
    "    for team_id in dict_map[map_id]:\n",
    "\n",
    "        count_team = count_team + 1\n",
    "\n",
    "        weighted_rating    = []\n",
    "        # weighted_kast      = []\n",
    "        # weighted_kpr       = []\n",
    "        # weighted_round_dif = []\n",
    "\n",
    "        prize = []\n",
    "\n",
    "        for player_id in dict_map[map_id][team_id]['players_id']:            \n",
    "\n",
    "            #df_aux = dict_player[player_id][ dict_player[player_id]['map']==map_name ]\n",
    "\n",
    "            df_aux = dict_player[player_id]\n",
    "\n",
    "            date_vec = (map_date-df_aux['date']).astype('timedelta64[D]')\n",
    "\n",
    "            # date_vec = (map_date-dict_player[player_id]['date']).astype('timedelta64[D]')\n",
    "\n",
    "            # df_op_rank = df_tmp[ df_tmp['team_rank_1'] ]\n",
    "\n",
    "            # df_aux = dict_player[player_id][ (date_vec>1) & (date_vec<DAYS_WEIGHT)  ]\n",
    "\n",
    "            #df_aux = dict_player[player_id][ (date_vec>1) & (date_vec<DAYS_WEIGHT) ]\n",
    "\n",
    "            # df_aux = df_aux[ df_aux['map']==map_name ]\n",
    "\n",
    "            df_aux = df_aux[ (date_vec>1) & (date_vec<DAYS_WEIGHT) ]\n",
    "\n",
    "            try:\n",
    "                m = float(1.0)/ sum( date_vec[(date_vec>1) & (date_vec<DAYS_WEIGHT)]-DAYS_WEIGHT )\n",
    "            except:\n",
    "                m = 0.0\n",
    "\n",
    "            w_i = m * (date_vec[(date_vec>1) & (date_vec<DAYS_WEIGHT)] - DAYS_WEIGHT)\n",
    "            \n",
    "            weighted_rating.append( sum(df_aux['rating'] * w_i) )\n",
    "\n",
    "            # weighted_kast.append( sum(df_aux['KAST'] * w_i / 100.0) )\n",
    "            # weighted_kpr.append( sum(df_aux['kills_per_round'] * w_i) )\n",
    "            \n",
    "\n",
    "            # weighted_round_dif.append( sum( (df_aux['team_score']-df_aux['op_score']) * w_i) )\n",
    "\n",
    "            prize.append( df_aux['prize'].sum() )\n",
    "\n",
    "        order = np.argsort( weighted_rating )\n",
    "\n",
    "        # if count_team == fav:\n",
    "        #     count_p = -1\n",
    "        #     for ind in order:\n",
    "        #         count_p = count_p + 1\n",
    "        #         dict_train[map_id]['t_0_p_'+str(count_p)+'_rating'] = weighted_rating[ind]\n",
    "        #         dict_train[map_id]['t_0_p_'+str(count_p)+'_kast'] = weighted_rating[ind]\n",
    "        #         dict_train[map_id]['t_0_p_'+str(count_p)+'_kpr'] = weighted_rating[ind]\n",
    "        # else:\n",
    "        #     count_p = -1\n",
    "        #     for ind in order:\n",
    "        #         count_p = count_p + 1\n",
    "        #         dict_train[map_id]['t_1_p_'+str(count_p)+'_rating'] = weighted_rating[ind]\n",
    "        #         dict_train[map_id]['t_1_p_'+str(count_p)+'_kast'] = weighted_rating[ind]\n",
    "        #         dict_train[map_id]['t_1_p_'+str(count_p)+'_kpr'] = weighted_rating[ind]\n",
    "\n",
    "        if count_team == fav:\n",
    "\n",
    "            dict_train[map_id]['t0_prize'] = np.average( prize )\n",
    "\n",
    "            dict_train[map_id]['t_0_avg_rating'] = np.average( weighted_rating )\n",
    "            # dict_train[map_id]['t_0_std_rating'] = np.std( weighted_rating )\n",
    "\n",
    "            # dict_train[map_id]['t_0_avg_kast'] = np.average( weighted_kast )\n",
    "            # dict_train[map_id]['t_0_std_kast'] = np.std( weighted_kast )\n",
    "\n",
    "            # dict_train[map_id]['t_0_avg_kpr'] = np.average( weighted_kpr )\n",
    "            # dict_train[map_id]['t_0_std_kpr'] = np.std( weighted_kpr )\n",
    "\n",
    "            # dict_train[map_id]['t_0_avg_rd'] = np.average( weighted_round_dif )\n",
    "            # dict_train[map_id]['t_0_std_rd'] = np.std( weighted_round_dif )\n",
    "\n",
    "        else:\n",
    "\n",
    "            dict_train[map_id]['t1_prize'] = np.average( prize )\n",
    "\n",
    "            dict_train[map_id]['t_1_avg_rating'] = np.average( weighted_rating )\n",
    "            # dict_train[map_id]['t_1_std_rating'] = np.std( weighted_rating )\n",
    "\n",
    "            # dict_train[map_id]['t_1_avg_kast'] = np.average( weighted_kast )\n",
    "            # dict_train[map_id]['t_1_std_kast'] = np.std( weighted_kast )\n",
    "\n",
    "            # dict_train[map_id]['t_1_avg_kpr'] = np.average( weighted_kpr )\n",
    "            # dict_train[map_id]['t_1_std_kpr'] = np.std( weighted_kpr )\n",
    "\n",
    "            # dict_train[map_id]['t_1_avg_rd'] = np.average( weighted_round_dif )\n",
    "            # dict_train[map_id]['t_1_std_rd'] = np.std( weighted_round_dif )\n",
    "\n",
    "    \n",
    "\n",
    "time_2 = datetime.now()\n",
    "\n",
    "print( time_2-time_1 )\n",
    "#date_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we process the results we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Index(['rank_dif', 'fav_win', 't0_prize', 't_0_avg_rating', 't1_prize',\n       't_1_avg_rating', 'rating_dif', 'prize_rating_dif'],\n      dtype='object')\n"
    },
    {
     "data": {
      "text/plain": "0.606"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train = pd.DataFrame.from_dict(dict_train,orient='index')\n",
    "\n",
    "for map_id in df_train.index:\n",
    "    df_train.at[map_id,'rating_dif'] = (dict_train[map_id]['t_0_avg_rating'] - dict_train[map_id]['t_1_avg_rating'])\n",
    "\n",
    "    if dict_train[map_id]['t0_prize'] > 0:\n",
    "        dict_train[map_id]['t0_prize_rating'] = np.log(dict_train[map_id]['t0_prize']) / 12.0\n",
    "    else:\n",
    "        dict_train[map_id]['t0_prize_rating'] = 0.0\n",
    "\n",
    "    if dict_train[map_id]['t1_prize'] > 0:\n",
    "        dict_train[map_id]['t1_prize_rating'] = np.log(dict_train[map_id]['t1_prize']) / 12.0\n",
    "    else:\n",
    "        dict_train[map_id]['t1_prize_rating'] = 0.0\n",
    "\n",
    "\n",
    "    df_train.at[map_id,'prize_rating_dif'] = dict_train[map_id]['t0_prize_rating'] - dict_train[map_id]['t1_prize_rating'] \n",
    "    #df_train.at[map_id,'kast_dif'] = 1.0*(dict_train[map_id]['t_0_avg_kast'] - dict_train[map_id]['t_1_avg_kast'])**1\n",
    "    #df_train.at[map_id,'rank_rating'] = df_train.at[map_id,'t_1_avg_rating'] / df_train.at[map_id,'rank_dif']\n",
    "\n",
    "\n",
    "df_train = df_train.fillna(0)\n",
    "\n",
    "print(df_train.keys())\n",
    "\n",
    "df_train['fav_win'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank_dif</th>\n      <th>fav_win</th>\n      <th>t0_prize</th>\n      <th>t_0_avg_rating</th>\n      <th>t1_prize</th>\n      <th>t_1_avg_rating</th>\n      <th>rating_dif</th>\n      <th>prize_rating_dif</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>79922</th>\n      <td>9</td>\n      <td>0</td>\n      <td>1304.666667</td>\n      <td>1.055806</td>\n      <td>3854.166667</td>\n      <td>1.079054</td>\n      <td>-0.023249</td>\n      <td>-0.090267</td>\n    </tr>\n    <tr>\n      <th>79923</th>\n      <td>9</td>\n      <td>0</td>\n      <td>1304.666667</td>\n      <td>1.055806</td>\n      <td>3854.166667</td>\n      <td>1.079054</td>\n      <td>-0.023249</td>\n      <td>-0.090267</td>\n    </tr>\n    <tr>\n      <th>79943</th>\n      <td>80</td>\n      <td>1</td>\n      <td>6333.333333</td>\n      <td>1.098823</td>\n      <td>1613.833333</td>\n      <td>1.081069</td>\n      <td>0.017754</td>\n      <td>0.113935</td>\n    </tr>\n    <tr>\n      <th>79945</th>\n      <td>80</td>\n      <td>0</td>\n      <td>6333.333333</td>\n      <td>1.098823</td>\n      <td>1613.833333</td>\n      <td>1.081069</td>\n      <td>0.017754</td>\n      <td>0.113935</td>\n    </tr>\n    <tr>\n      <th>79947</th>\n      <td>80</td>\n      <td>0</td>\n      <td>6333.333333</td>\n      <td>1.098823</td>\n      <td>1613.833333</td>\n      <td>1.081069</td>\n      <td>0.017754</td>\n      <td>0.113935</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "       rank_dif  fav_win     t0_prize  t_0_avg_rating     t1_prize  \\\n79922         9        0  1304.666667        1.055806  3854.166667   \n79923         9        0  1304.666667        1.055806  3854.166667   \n79943        80        1  6333.333333        1.098823  1613.833333   \n79945        80        0  6333.333333        1.098823  1613.833333   \n79947        80        0  6333.333333        1.098823  1613.833333   \n\n       t_1_avg_rating  rating_dif  prize_rating_dif  \n79922        1.079054   -0.023249         -0.090267  \n79923        1.079054   -0.023249         -0.090267  \n79943        1.081069    0.017754          0.113935  \n79945        1.081069    0.017754          0.113935  \n79947        1.081069    0.017754          0.113935  "
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ">               precision    recall  f1-score   support\n\nUnderdog wins       0.70      0.23      0.34       193\nFavorite wins       0.66      0.94      0.77       307\n\n     accuracy                           0.66       500\n    macro avg       0.68      0.58      0.56       500\n weighted avg       0.67      0.66      0.61       500\n\n[[ 44 149]\n [ 19 288]]\n0.664\n"
    },
    {
     "data": {
      "text/plain": "0.6997350255691887"
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the features that we want\n",
    "df_tmp = df_train.drop(['rank_dif', 't0_prize', 't_0_avg_rating', 't1_prize',\n",
    "        't_1_avg_rating'],axis=1)\n",
    "\n",
    "# Drop nothing\n",
    "#df_tmp = df_train.drop(['rank_dif','t0_prize', 't1_prize','rating_dif','prize_rating_dif','t_1_avg_rating'],axis=1)\n",
    "\n",
    "# Divide data set into training and testing sets      \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_tmp.drop(['fav_win'],axis=1),df_tmp['fav_win'], test_size=0.25)\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['fav_win','rank_dif'],axis=1),df_train['fav_win'], test_size=0.25)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(x_orig,y_orig, test_size=0.25)\n",
    "\n",
    "# Make an instance of the model, and increase the maximum number of iterations to avoid convergence problems\n",
    "logmodel = LogisticRegression(max_iter=800)\n",
    "\n",
    "# Training for the model\n",
    "logmodel.fit(X_train,y_train)\n",
    "\n",
    "# Now we use the testing data set to make predictions and evaluate the model's performance\n",
    "predictions = logmodel.predict(X_test)\n",
    "\n",
    "print('>'+classification_report(y_test,predictions,target_names=['Underdog wins','Favorite wins']))\n",
    "\n",
    "#predictions[:] = 1\n",
    "\n",
    "#c_mat = confusion_matrix(y_test.values, predictions)\n",
    "c_mat = confusion_matrix(y_test, predictions)\n",
    "print( c_mat )\n",
    "\n",
    "accuracy = (c_mat[0][0] + c_mat[1][1]) / np.sum(c_mat)\n",
    "print(accuracy)\n",
    "\n",
    "y_scores = logmodel.predict_proba(X_test)[:,1]\n",
    "\n",
    "roc_auc_score(y_test, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fav_win</th>\n      <th>t_0_avg_rating</th>\n      <th>t_1_avg_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>79922</th>\n      <td>0</td>\n      <td>1.055806</td>\n      <td>1.079054</td>\n    </tr>\n    <tr>\n      <th>79923</th>\n      <td>0</td>\n      <td>1.055806</td>\n      <td>1.079054</td>\n    </tr>\n    <tr>\n      <th>79943</th>\n      <td>1</td>\n      <td>1.098823</td>\n      <td>1.081069</td>\n    </tr>\n    <tr>\n      <th>79945</th>\n      <td>0</td>\n      <td>1.098823</td>\n      <td>1.081069</td>\n    </tr>\n    <tr>\n      <th>79947</th>\n      <td>0</td>\n      <td>1.098823</td>\n      <td>1.081069</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "       fav_win  t_0_avg_rating  t_1_avg_rating\n79922        0        1.055806        1.079054\n79923        0        1.055806        1.079054\n79943        1        1.098823        1.081069\n79945        0        1.098823        1.081069\n79947        0        1.098823        1.081069"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[ 81 112]\n [ 52 255]]\n>               precision    recall  f1-score   support\n\nUnderdog wins       0.61      0.42      0.50       193\nFavorite wins       0.69      0.83      0.76       307\n\n     accuracy                           0.67       500\n    macro avg       0.65      0.63      0.63       500\n weighted avg       0.66      0.67      0.66       500\n\n"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test with different tresholds\n",
    "y_scores = logmodel.predict_proba(X_test)[:,1]\n",
    "predictions = (y_scores > 0.55) *1\n",
    "#print(predictions)\n",
    "\n",
    "c_mat = confusion_matrix(y_test, predictions)\n",
    "print( c_mat )\n",
    "\n",
    "print('>'+classification_report(y_test,predictions,target_names=['Underdog wins','Favorite wins']))\n",
    "roc_auc_score(y_test, y_scores)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "plt.figure(figsize=(10,8));\n",
    "# plot_roc_curve(logmodel, X_test, y_test,ax='ax')  # doctest: +SKIP\n",
    "\n",
    "# ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "#         label='Chance', alpha=.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.58217396 0.70538484 0.62385906 0.58364854 0.52852056 0.51313207\n 0.57512057 0.56297732 0.68300915 0.51485599 0.59261334 0.54575573\n 0.54091634 0.64784133 0.62040165 0.71631764 0.60675222 0.58767929\n 0.55483196 0.53123342 0.9066794  0.50870046 0.6857333  0.58413612\n 0.49861967 0.63555062 0.54262391 0.70538465 0.63859271 0.81966956\n 0.49594607 0.51367837 0.56477698 0.54542274 0.52908915 0.66438087\n 0.51218395 0.66114491 0.57925142 0.60436657 0.59966738 0.6165169\n 0.53574472 0.6564637  0.81954772 0.73763471 0.51392463 0.71414087\n 0.57559163 0.61344341 0.5400597  0.5251716  0.50435511 0.66852658\n 0.54169512 0.52948996 0.89381201 0.71546403 0.6802322  0.58063817\n 0.57885408 0.65613107 0.58641499 0.61588786 0.62632493 0.49560392\n 0.50482653 0.58190807 0.59546567 0.67644279 0.60380139 0.5085201\n 0.47253415 0.56453124 0.64380454 0.53619415 0.52169954 0.52856139\n 0.52128307 0.53865538 0.76305929 0.96253808 0.54270941 0.53174004\n 0.5059786  0.55870407 0.53262191 0.67448515 0.58495348 0.6080701\n 0.50846247 0.62632493 0.5650393  0.70824771 0.57932896 0.59328938\n 0.52385497 0.6399401  0.93101412 0.52614132 0.55770204 0.50335865\n 0.50377605 0.57614667 0.71133933 0.54804408 0.50816601 0.53034195\n 0.55763907 0.54262391 0.58533626 0.67316457 0.52855722 0.57517105\n 0.52178749 0.5457605  0.72766196 0.557765   0.53994167 0.50484741\n 0.5795566  0.53809761 0.61999397 0.71256732 0.66114491 0.52549371\n 0.5464367  0.53146677 0.64686087 0.65047321 0.69492114 0.50376959\n 0.61240048 0.5814885  0.53535755 0.69051153 0.5544639  0.50677742\n 0.54736128 0.53223187 0.55819099 0.62274741 0.69332579 0.51798416\n 0.55886733 0.54924889 0.56389991 0.54881681 0.86673413 0.59594629\n 0.55962935 0.5841739  0.53223187 0.60672091 0.55281843 0.54997071\n 0.54997071 0.58364854 0.89876152 0.6735191  0.64120367 0.60999247\n 0.91457218 0.55404307 0.8552509  0.54575573 0.59328938 0.50940863\n 0.52652452 0.59676801 0.55663329 0.66367043 0.53931655 0.57169593\n 0.51565131 0.5069303  0.52047391 0.51054901 0.51726599 0.53368916\n 0.5085201  0.48727926 0.51071676 0.83329973 0.93101412 0.75598559\n 0.59416502 0.58414066 0.54394518 0.52939843 0.69378667 0.52330344\n 0.62557032 0.60436657 0.62733714 0.59744015 0.54711231 0.51620087\n 0.6857333  0.48456436 0.67063064 0.57128942 0.55475652 0.67252798\n 0.52852056 0.51368432 0.4992273  0.50948001 0.61908703 0.59797134\n 0.53931655 0.52753278 0.56401544 0.55281843 0.76378855 0.59777265\n 0.56737023 0.54182456 0.64023567 0.68235217 0.57813466 0.55279895\n 0.52548675 0.5758811  0.56422975 0.59456449 0.66438087 0.64596965\n 0.56937031 0.55922428 0.5392653  0.5729107  0.50544813 0.56412925\n 0.50948001 0.73763471 0.5550322  0.53300665 0.55336643 0.48653749\n 0.51724196 0.65304351 0.59780594 0.64073765 0.57532385 0.57607182\n 0.5550322  0.72164243 0.59911776 0.50113899 0.51136574 0.6735191\n 0.64076763 0.51338064 0.51725364 0.66180582 0.5520803  0.54861764\n 0.50828589 0.52543727 0.57746496 0.59111277 0.61908703 0.51804198\n 0.50682155 0.5586674  0.61929799 0.51118674 0.54390229 0.52894607\n 0.68149014 0.60275256 0.56122662 0.5586674  0.54253475 0.51485599\n 0.56697137 0.59423309 0.54636103 0.5328851  0.56890889 0.52154881\n 0.5113056  0.67644279 0.52534708 0.62040165 0.5328851  0.58996818\n 0.52767496 0.52047391 0.5029311  0.80220345 0.54497475 0.5086032\n 0.66457999 0.66067873 0.67255742 0.51536045 0.50811253 0.68943728\n 0.52953261 0.53367917 0.51999911 0.59433667 0.54116758 0.51894947\n 0.66180582 0.69492114 0.58959611 0.57492105 0.55819099 0.79948601\n 0.5397256  0.5685949  0.61881857 0.79950273 0.64114841 0.53880753\n 0.51118674 0.65156489 0.66572663 0.57993115 0.56737023 0.52861699\n 0.55589475 0.52554031 0.55408704 0.63038586 0.64426996 0.66808022\n 0.63179476 0.6285957  0.5993389  0.51189715 0.67782756 0.61290994\n 0.5293909  0.55219678 0.51118674 0.53503145 0.50026655 0.65156489\n 0.52491477 0.46062968 0.53816001 0.5331324  0.51144678 0.51434899\n 0.6069756  0.64607424 0.61060955 0.53476893 0.49674925 0.52933495\n 0.52420675 0.68418872 0.62234138 0.51313868 0.62140304 0.58646671\n 0.5293909  0.51363741 0.64364936 0.54817062 0.50401667 0.56442318\n 0.52619586 0.54997071 0.58352844 0.60422488 0.53024161 0.63859271\n 0.57747838 0.53600649 0.61060955 0.60441917 0.6399401  0.50565561\n 0.54655415 0.64516364 0.53218308 0.5455946  0.53062319 0.52537965\n 0.53251896 0.5110215  0.58668783 0.5650393  0.58678731 0.54091602\n 0.66125909 0.5265246  0.55389603 0.53237663 0.52953261 0.58034363\n 0.64025121 0.54017717 0.51227035 0.59964081 0.55161236 0.72475147\n 0.6647754  0.65589769 0.60738408 0.6285957  0.5550322  0.74300249\n 0.51368432 0.51999911 0.62757631 0.56412925 0.59656657 0.52154881\n 0.64426996 0.64439162 0.55792265 0.73763471 0.60012788 0.60024909\n 0.50583782 0.61929799 0.56890889 0.55756044 0.53791044 0.5377051\n 0.52169954 0.54031798 0.55792262 0.51811252 0.52906947 0.50113899\n 0.60436686 0.56534025 0.89381201 0.56511187 0.51830903 0.51514425\n 0.52420675 0.52908915 0.75598559 0.66181235 0.56625598 0.50677084\n 0.55445182 0.52345174 0.49849891 0.73826218 0.61200086 0.81617282\n 0.55577411 0.66367043 0.6010185  0.69215711 0.53033867 0.81657945\n 0.55870407 0.68623477 0.54191569 0.5853254  0.5547093  0.58641499\n 0.58103097 0.52325097 0.8418465  0.53062319 0.58767929 0.5301618\n 0.70294449 0.57347358 0.54298984 0.52908829 0.69717461 0.59118839\n 0.58996818 0.52843302 0.72025185 0.51367837 0.52614132 0.61566206\n 0.56436065 0.59072919 0.50418282 0.51842768 0.71842935 0.57552744\n 0.60398391 0.64726855 0.53718241 0.53047332 0.52240651 0.5018889\n 0.51363741 0.58959611 0.57595372 0.61929799 0.53062319 0.51062749\n 0.65613107 0.57669976]\n"
    }
   ],
   "source": [
    "print(y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4.32149969, 3.07989256]])"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}